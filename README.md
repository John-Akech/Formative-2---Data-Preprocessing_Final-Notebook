# **Data Preprocessing and Augmentation Project**  

## **Overview**  
This project focuses on **preparing customer transaction data** for machine learning. Our key tasks include:  
âœ… **Cleaning data** (handling missing values, ensuring quality)  
âœ… **Augmenting data** (generating synthetic data using SMOTE/interpolation)  
âœ… **Merging datasets** (combining related but indirect data sources)  
âœ… **Feature engineering** (extracting insights like moving averages & engagement scores)  
âœ… **Bonus: Training ML models** (predicting customer spending behavior)  

This project was developed by **Group 17**:  
- **John Akech**  
- **Geu Aguto Garang**  
- **Kuir Juach Kuir Thuch**  

---

## ğŸ“Œ **Table of Contents**  
1. [Prerequisites](#prerequisites)  
2. [Dataset Description](#dataset-description)  
3. [How to Run the Code](#how-to-run-the-code)  
4. [Project Structure](#project-structure)  
5. [Workflow Breakdown](#workflow-breakdown)  
6. [Outputs](#outputs)  
7. [Challenges & Solutions](#challenges-&-solutions)  

---

## ğŸ›  **Prerequisites**  
Before running the code, make sure you have:  
- **Python 3.8+**  
- **Jupyter Notebook** (if using `.ipynb`)  
- The following Python libraries:  

```bash
pip install pandas numpy scikit-learn imbalanced-learn xgboost matplotlib seaborn
```  

---

## ğŸ“Š **Dataset Description**  
Weâ€™re using three datasets:  
ğŸ“Œ **`customer_transactions.csv`** â†’ Transaction details (amounts, categories, ratings)  
ğŸ“Œ **`customer_social_profiles.csv`** â†’ Customer social data  
ğŸ“Œ **`id_mapping.csv`** â†’ Mapping file to link datasets  

Make sure these files are in the same directory as our code!  

---

## ğŸš€ **How to Run the Code**  

### **Step 1: Clone the Repository**  
If the project is on GitHub, use:  

```bash
git clone git@github.com:John-Akech/Formative-2---Data-Preprocessing_Final-Notebook.git
cd Formative-2---Data-Preprocessing_Final-Notebook
```  

Or download and place the files in your working directory.  

### **Step 2: Open the Notebook**  
For the Jupyter Notebook version:  

```bash
jupyter notebook Formative_2_Data_Preprocessing.ipynb
```  

For the Python script version:  

```bash
python main.py
```  

### **Step 3: Run the Code**  
Go step by step:  
1ï¸âƒ£ Load `customer_transactions.csv`  
2ï¸âƒ£ Clean and handle missing values  
3ï¸âƒ£ Generate synthetic data  
4ï¸âƒ£ Merge datasets with `id_mapping.csv`  
5ï¸âƒ£ Perform quality checks  
6ï¸âƒ£ (Bonus) Train ML models to predict spending  

---

## ğŸ“‚ **Project Structure**  

```
â”œâ”€â”€ README.md                     # This file  
â”œâ”€â”€ Formative 2 - Data Preprocessing.ipynb  # Notebook version  
â”œâ”€â”€ data_files/                    # Input datasets  
â”‚   â”œâ”€â”€ customer_transactions.csv  
â”‚   â”œâ”€â”€ customer_social_profiles.csv  
â”‚   â”œâ”€â”€ id_mapping.csv  
â”œâ”€â”€ model_files/                   # Trained models  
â”‚   â”œâ”€â”€ linear_regression_model.pkl  
â”‚   â”œâ”€â”€ random_forest_model.pkl  
â”‚   â”œâ”€â”€ xgboost_model.pkl  
â”œâ”€â”€ outputs/                       # Processed data  
â”‚   â”œâ”€â”€ customer_transactions_augmented.csv  
â”‚   â”œâ”€â”€ final_customer_data_group17.csv  
â”‚   â”œâ”€â”€ final_dataset_ready_group17.csv  
```  

---

## ğŸ”¬ **Workflow Breakdown**  

### **1ï¸âƒ£ Data Cleaning**  
âœ” Handle missing values (median/mode imputation)  
âœ” Encode categorical variables  

### **2ï¸âƒ£ Data Augmentation**  
âœ” Apply random noise to numerical data  
âœ” Use **SMOTE** to balance data  

### **3ï¸âƒ£ Merging Datasets**  
âœ” Link datasets using `id_mapping.csv`  
âœ” Aggregate duplicate data  

### **4ï¸âƒ£ Feature Engineering**  
âœ” Calculate moving averages  
âœ” Generate engagement scores  
âœ” Convert text data using **TF-IDF**  

### **5ï¸âƒ£ ML Model Training (Bonus)**  
âœ” Train **Linear Regression, Random Forest, XGBoost**  
âœ” Evaluate models (MAE, MSE, RÂ² score)  

---

## ğŸ¯ **Outputs**  

âœ… **Augmented Dataset:** `customer_transactions_augmented_<timestamp>.csv`  
âœ… **Final Processed Dataset:** `final_customer_data_group17.csv`  
âœ… **Trained Models:** Saved in `model_files/`  
âœ… **Model Evaluation:** Printed in the notebook/script  

---

## âš ï¸ **Challenges & Solutions**  

### ğŸ”¹ **Challenge 1: Missing Values in Target Variable**  
**Problem**: Some target values were missing.  
**Fix**: Dropped those rows and handled missing data in features.  

### ğŸ”¹ **Challenge 2: Inconsistent Column Names**  
**Problem**: Merging was tricky due to different column names.  
**Fix**: Used `id_mapping.csv` to standardize IDs.  

### ğŸ”¹ **Challenge 3: Imbalanced Customer Ratings**  
**Problem**: Biased predictions due to class imbalance.  
**Fix**: Used **SMOTE** to generate synthetic samples.  

### ğŸ”¹ **Challenge 4: Handling Text Data**  
**Problem**: The `review_sentiment` column was unstructured.  
**Fix**: Used **TF-IDF** to convert text into numerical features.  


---

### ğŸ‰ Thatâ€™s it! Happy coding! ğŸš€  
